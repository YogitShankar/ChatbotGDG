{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure PyTorch uses a single thread for better efficiency in small-scale tasks\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# Load text files from a directory\n",
    "def load_text_files_from_directory(directory):\n",
    "    files_content = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if os.path.isfile(file_path) and file_path.endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                files_content.append(file.read().strip())\n",
    "    return files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine problem statements and editorials\n",
    "def combine_problems_and_editorials(problem_statements_path, editorials_path):\n",
    "    problems = load_text_files_from_directory(problem_statements_path)\n",
    "    editorials = load_text_files_from_directory(editorials_path)\n",
    "    combined = [f\"Problem: {p}\\n\\nEditorial: {e}\" for p, e in zip(problems, editorials)]\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Generation\n",
    "class CodeBERTEmbedder:\n",
    "    def __init__(self, model_name='microsoft/codebert-base'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def generate_embedding(self, text):\n",
    "        tokens = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "        return embedding.numpy()\n",
    "\n",
    "    def batch_generate_embeddings(self, texts, batch_size=2):\n",
    "        all_embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            tokens = self.tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**tokens)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "            all_embeddings.append(embeddings)\n",
    "        return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store Implementation\n",
    "class VectorStore:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.texts = []\n",
    "\n",
    "    def add_embeddings(self, texts, embeddings):\n",
    "        self.data = embeddings\n",
    "        self.texts = texts\n",
    "        self.nn = NearestNeighbors(n_neighbors=1, metric='cosine').fit(embeddings)\n",
    "\n",
    "    def search(self, query_embedding, k=1):\n",
    "        distances, indices = self.nn.kneighbors([query_embedding], n_neighbors=k)\n",
    "        results = [(self.texts[idx], 1 - distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Implementation\n",
    "class RAGRetriever:\n",
    "    def __init__(self, embedder, vector_store):\n",
    "        self.embedder = embedder\n",
    "        self.vector_store = vector_store\n",
    "\n",
    "    def retrieve_context(self, query, top_k=1):\n",
    "        query_embedding = self.embedder.generate_embedding(query)\n",
    "        results = self.vector_store.search(query_embedding, k=top_k)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: I am solving a Competitive Programming problem, and I need help understanding its editorial.\n",
      "Answer my questions regarding the editorial.\n",
      "\n",
      "\n",
      "Context: Problem: You are given a positive integer n.\n",
      "In this problem, the MEX of a collection of integers c1,c2,…,ck is defined as the smallest positive integer x which does not occur in the collection c. \n",
      "The primality of an array a1,…,an is defined as the number of pairs (l,r) such that 1≤l≤r≤n and MEX(al,…,ar) is a prime number. \n",
      "Find any permutation of 1,2,…,n with the maximum possible primality among all permutations of 1,2,…,n. \n",
      "Note: \n",
      "  A prime number is a number greater than or equal to 2 that is not divisible by any positive integer except 1 and itself. For example, 2,5,13 are prime numbers, but 1 and 6 are not prime numbers.  A permutation of 1,2,…,n is an array consisting of n distinct integers from 1 to n in arbitrary order. For example, [2,3,1,5,4] is a permutation, but [1,2,2] is not a permutation (2 appears twice in the array), and [1,3,4] is also not a permutation (n=3 but there is 4 in the array).\n",
      "\n",
      "Editorial: Problem 1844/B\n",
      "Hint 1 \n",
      " In order for (l,r) to contribute to the primality, we must have MEX(al,…,ar)≥2, so there is some value 1 between indices l and r. \n",
      "Hint 2 \n",
      " To maximize the number of pairs (l,r) that contain the value 1, we should put 1 near the middle of the array. \n",
      "Hint 3 \n",
      " To minimize the number of pairs (l,r) where MEX(al,…,ar)≥2 but is not prime, we should put 2 and 3 at the ends of the array. \n",
      "Solution \n",
      " 1844B - Permutations & PrimesThe cases n≤2 can be handled separately. For n≥3, any construction with a1=2,a⌊(n+1)/2⌋=1,an=3 is optimal. We can prove this as follows: Note that since 2 and 3 are both prime, any (l,r) with l≤⌊n+12⌋≤r has a prime MEX(al,…,ar) except for possibly (l,r)=(1,n), where MEX(a1,…,an)=n+1. Therefore the primality of this array is ⌊n+12⌋⋅⌈n+12⌉−[n+1 is not prime], where [P]=1 if proposition P is true and 0 if P is false. On the other hand, for any permutation of 1,…,n, let k be the index with ak=1. The primality of this array cannot exceed k(n+1−k)−[n+1 is not prime], since any pair (l,r) with prime MEX(al,…,ar)≥2 must satisfy l≤k≤r, and additionally MEX(a1,…,an)=n+1 no matter what the permutation is. The function f(k)=k(n+1−k) is a quadratic which is maximized at k=⌊n+12⌋, so k(n+1−k)−[n+1 is not prime]≤⌊n+12⌋⋅⌈n+12⌉−[n+1 is not prime] as required.The time complexity is O(n) (note that we don't even need to sieve for primes!). \n",
      "Implementation \n",
      " #include <bits/stdc++.h>\n",
      "using namespace std;\n",
      "\n",
      "int a[200000];\n",
      "int main() {\n",
      "    int i;\n",
      "    int t,n;\n",
      "    scanf(\"%d\",&t);\n",
      "    while (t--) {\n",
      "        scanf(\"%d\",&n);\n",
      "        if (n == 1) printf(\"1\\n\");\n",
      "        else if (n == 2) printf(\"1 2\\n\");\n",
      "        else {\n",
      "            int c = 4;\n",
      "            fill(a,a+n,0);\n",
      "            a[0] = 2,a[n/2] = 1,a[n-1] = 3;\n",
      "            for (i = 0; i < n; i++) {\n",
      "                if (a[i] == 0) a[i] = c++;\n",
      "            }\n",
      "            for (i = 0; i < n; i++) printf(\"%d%c\",a[i],(i == n-1) ? '\\n':' ');\n",
      "        }\n",
      "    }\n",
      "    return 0;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Chatbot Integration\n",
    "class CPChatbot:\n",
    "    def __init__(self, retriever, system_message):\n",
    "        self.retriever = retriever\n",
    "        self.system_message = system_message\n",
    "\n",
    "    def chat(self, user_query):\n",
    "        contexts = self.retriever.retrieve_context(user_query)\n",
    "        response = f\"System: {self.system_message}\\n\\n\"\n",
    "        response += f\"Context: {contexts[0][0]}\"\n",
    "        return response\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    EDITORIALS_PATH = r\"C:\\Users\\Aaryan\\Desktop\\Chatbot2\\data\\editorials\"\n",
    "    PROBLEM_STATEMENTS_PATH = r\"C:\\Users\\Aaryan\\Desktop\\Chatbot2\\data\\problem_statements\"\n",
    "\n",
    "    # Combine problem statements and editorials\n",
    "    documents = combine_problems_and_editorials(PROBLEM_STATEMENTS_PATH, EDITORIALS_PATH)\n",
    "\n",
    "    # Initialize components\n",
    "    embedder = CodeBERTEmbedder()\n",
    "    vector_store = VectorStore()\n",
    "    retriever = RAGRetriever(embedder, vector_store)\n",
    "\n",
    "    # Generate embeddings and populate the vector store\n",
    "    embeddings = embedder.batch_generate_embeddings(documents)\n",
    "    vector_store.add_embeddings(documents, embeddings)\n",
    "\n",
    "    # Create chatbot\n",
    "    system_message = (\n",
    "        \"I am solving a Competitive Programming problem, and I need help understanding its editorial.\\n\"\n",
    "        \"Answer my questions regarding the editorial.\\n\"\n",
    "    )\n",
    "    chatbot = CPChatbot(retriever, system_message)\n",
    "\n",
    "    # Single query input\n",
    "    user_query = input(\"Enter your query: \")\n",
    "    print(chatbot.chat(user_query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
