Hint 1Can you reach the score max(a)+⌈n/2⌉?

Hint 2Can you reach the score max(a)+⌈n/2⌉−1?

SolutionThe maximum red element is ≤max(a), and the maximum number of red elements is ⌈n/2⌉. Can you reach the score max(a)+⌈n/2⌉?  If n is even, you always can, by either choosing all the elements in even positions or all the elements in odd positions (at least one of these choices contains max(a)). If n is odd, you can if and only if there is one occurrence of max(a) in an odd position. Otherwise, you can choose even positions and your score is max(a)+⌈n/2⌉−1. Complexity: O(n)

Hint 1Can you determine fast how many intervals contain point p?

Hint 2The intervals that contain point p are the ones with l≤p and r≥p.

Hint 3Determine how many intervals contain:  point x1; points x1+1,…,x2−1; point x2; … point xn. 

SolutionFirst, let's focus on determining how many intervals contain some point x. These intervals are the ones with l≤x and x≤r.So a point xi<p<xi+1 satisfies x1≤p,…,xi≤p, and p≤xi+1,…,p≤xn. It means that you have found xi+1−xi−1 points contained in exactly i(n−i) intervals (because there are i possible left endpoints and n−i possible right endpoints).Similarly, the point p=xi is contained in i(n−i+1)−1 intervals (you have to remove interval [xi,xi], which you do not draw).So you can use a map that stores how many points are contained in exactly x intervals, and update the map in the positions i(n−i) and i(n−i+1)−1.Complexity: O(nlogn)

Hint 1The answer is at most n.

Hint 2Solve the problem with k=0.

Hint 3When is the answer n?

Hint 4If the answer is not n, how can you buy cards?

SolutionNote that there are n types of cards, so the subsets have size at most n, and the answer is at most n.If k=0, you can make subsets of size s if and only if the following conditions are true:  the number of cards (m) is a multiple of s; the maximum number of cards of some type (x) is ≤m/s. Proof:  m is the number of decks times s. The number of decks is m/s. Each deck can contain at most 1 card of each type, so there are at most m/s cards of each type in total. If the two conditions above hold, you can make a deck containing the s types of cards with maximum frequency. You can show with some calculations that the conditions still hold after removing these cards. So you can prove by induction that the two conditions are sufficient to make decks of size s. The same idea is used in problems like 1954D - Colored Balls and abc227_d - Project Planning.For a generic k, the answer is n if you can make the number of cards of type 1,…,n equal. Otherwise, for any choice of number of cards to buy, you can buy them without changing x. It means that you need x⋅s cards in total:  if you have less than x⋅s cards, you have to check if you can reach x⋅s cards by buying at most k new cards; if you already have x⋅s or more cards at the beginning, you have to check if you can make m a multiple of s. Complexity: O(n)

Hint 1When is the answer 0?

Hint 2Starting from city x is equivalent to setting ax=1.

SolutionAt some time t, consider the minimal interval [l,r] that contains all the cities with ai≤t (let's call it "the minimal interval at time t"). You have to visit all this interval within time t, otherwise there are some cities with ai≤t which you do not visit in time. So if this interval has length >t, you cannot visit it all within time t, and the answer is 0.Otherwise, the answer is at least 1. A possible construction is visiting "the minimal interval at time 1", then "the minimal interval at time 2", ..., then "the minimal interval at time n". Note that, when you visit "the minimal interval at time t", the actual time is equal to the length of the interval, which is ≤t. In this way, at time t you will have conquered all the cities in the minimal interval at time t, and possibly other cities.Starting from city x is equivalent to setting ax=1. After this operation, you have to guarantee that, for each i, the minimal interval at time t is short enough. If this interval is [l,r] before the operation, it can become either [x,r] (if x<l), or [l,x] (if x>r), or stay the same. In all this cases, the resulting length must be ≤t. With some calculations (e.g., r−x+1≤t), you can get than x must be contained in [r−t+1,l+t−1]. So it's enough to calculate and intersect the intervals obtained at t=1,…,n, and print the length of the final interval.You can calculate the minimal intervals by iterating on the cities in increasing order of ai. Again, if the old interval is [l,r] and the new city has index x, the new possible intervals are [x,r], [l,r], [l,x].Another correct solution is to intersect the intervals [i−ai+1,i+ai−1]. The proof is contained in the editorial of 2018F3 - Speedbreaker Counting (Hard Version).Complexity: O(n)

Hint 1Solve for a fixed final depth of the leaves.

Hint 2Which nodes are "alive" if all leaves are at depth d at the end?

SolutionIf the final depth of the leaves is d, it's optimal to keep in the tree all the nodes at depth d and all their ancestors. These nodes are the only ones which satisfy the following two conditions:  their depth (ai) is ≤d; the maximum depth of a node in their subtree (bi) is ≥d. So every node is alive in the interval of depths [ai,bi]. The optimal d is the one contained in the maximum number of intervals.

Hint 1The optimal subsequence must contain at least one occurrence of the maximum.

Hint 2Iterate over the minimum, in decreasing order.

Hint 3You have some "connected components". How many elements can you pick from each component? How to make sure you have picked at least one occurrence of the maximum?

SolutionThe optimal subsequence must contain at least one occurrence of the maximum (r) (suppose it doesn't; then you can just add one occurrence, at the cost of removing at most two elements, and this does not make your score smaller).Now you can iterate over the minimum value (l), in decreasing order. At any moment, you can pick elements with values [l,r]. Then you have to support queries "insert pick-able element" and "calculate score".The pick-able elements make some "connected components" of size s, and you can pick ⌈s/2⌉ elements. You can maintain the components with a DSU.You also want to pick an element with value r. For each component, check if it contains r in a subsequence with maximum size. If this does not happen for any component, your score decreases by 1. All this information can be maintained by storing, for each component, if it contains r in even positions, and if it contains r in odd positions.Complexity: O(nα(n))

Hint 1Solve for a fixed m (size of the subsets).

Hint 2m=1 is easy. Can you do something similar for other m?

Hint 3Solve for a fixed k (number of subsets).

Hint 4If you have a O(nlogn) solution for a fixed m, note that there exists a faster solution!

SolutionLet's write a function max_k(m), which returns the maximum k such that there exists a partition of k valid sets containing m intervals each. max_k works in O(nlogn) in the following way (using a lazy segment tree):  (wlog) ri≤ri+1; for each i not intersecting the previous subset, add 1 on the interval [l[i],r[i]]; as soon as a point belongs to m intervals, they become a subset; return the number of subsets. For a given k, you can binary search the maximum m such that max_k(m) ≥k in O(nlog2n).The problem asks for the maximum mk. Since mk≤n, for any constant C either m≤C or k≤n/C. For C=(nlogn)1/2, the total complexity becomes O((nlogn)3/2), which is enough to solve 2018E1 - Complex Segments (Easy Version). You can also find max_k(m) for all m with a divide and conquer approach, and the complexity becomes O(n√nlogn) (see here).Now let's go back to max_k(m). It turns out you can implement it in O(nα(n)).First of all, let's make all the endpoints distinct, in such a way that two intervals intersect if and only if they were intersecting before.Let's maintain a binary string of size n, initially containing only ones, that can support the following queries:  set bit in position p to 0; find the nearest 1 to the left of position p. This can be maintained with DSU, where the components are the maximal intervals containing 100...00.Now let's reuse the previous solution (sweeping r from left to right), but instead of a segment tree we will maintain a binary string with the following information:  the positions >r store 1; the positions ≤r store 1 if and only if the value in that position (in the previous solution) is a suffix max. So the queries become:  add 1 to [l,r]:   r changes, so you have to set elements in [r′+1,r−1] to 0;    the only other element that changes is the nearest 1 to the left of position l, which does not represent a suffix max anymore.  find the maximum: it's equal to the number of suffix maximums, which depends on r and on the number of components. This solution allows us to replace a O(logn) factor with a O(α(n)) factor.Complexity: O(n√nα(n))[Bonus: there exists a data structure faster than DSU to solve the subproblem above, so you can solve the problem in O(n√n). See here.]

Hint 1Suppose you are given a starting city and you want to win. Find several strategies to win (if possible) and try to work with the simplest ones.

Hint 2The valid starting cities are either zero, or all the cities in I:=∩ni=1[i−ai+1,i+ai−1]=[l,r].

Hint 3Now you have some bounds on the ai.

Hint 4Fix the interval I and try to find a (slow) DP.

Hint 5Counting paths seems easier than counting arrays. Make sure that, for each array, you make exactly one path (or a number of paths which is easy to handle).

Hint 6How many distinct states do you calculate in your DP?

SolutionLemma 1For a fixed starting city, if you can win, this strategy works:  [Strategy 1] If there is a city on the right whose distance is t and whose deadline is in t turns, go to the right. Otherwise, go to the left. Proof:  All constraints on the right hold. This strategy minimizes the time to reach any city on the left. So, if any strategy works, this strategy works too. CorollaryFor a fixed starting city, if you can win, this strategy works:  [Strategy 2] If there is a city whose distance is t and whose deadline is in t turns, go to that direction. Otherwise, go to any direction. Lemma 2The valid starting cities are either zero, or all the cities in I:=∩ni=1[i−ai+1,i+ai−1]=[l,r].Proof:  The cities outside I are losing, because there exists at least one unreachable city. Let's start from any city x in I, and use Strategy 2. You want to show that, for any x in I, Strategy 2 can visit all cities in I first, then all the other cities. Then, you can conclude that either all the cities in I are winning, or they are all losing. The interval I gives bounds on the ai: specifically, ai≥max(i−l+1,r−i+1). Then, you can verify that visiting the interval I first does not violate Strategy 2. CorollaryIf you use Strategy 1, the first move on the right determines l.O(n4) DPLet's iterate on the (non-empty) interval I. Let's calculate the bounds ai≥max(i−l+1,r−i+1). Note that Strategy 1 is deterministic (i.e., it gives exactly one visiting order for each fixed pair (starting city, a)). From now, you will use Strategy 1.Now you will calculate the number of pairs (a, visiting order) such that the cities in I are valid starting cities (and there might be other valid starting cities).Let's define dp[i][j][k] = number of pairs (a, visiting order), restricted to the interval [i,j], where k= "are you forced to go to the right in the next move?". Here are the main ideas to find the transitions:  If you go from [i+1,j] to [i,j], you must ensure that ai≥max(i−l+1,r−i+1,j−i+1) (because you visit it at time j−i+1). Also, k must be 0. If you go from [i,j−1] to [i,j], and you want to make k=0, you must make aj=j−i+1. It means that j was the city that was enforcing you to go to the right. In my code, the result is stored in int_ans[i][j].Now you want to calculate the number of pairs (a, visiting order) such that the cities in I are the only valid starting cities. This is similar to 2D prefix sums, and it's enough to make int_ans[i][j] -= int_ans[i - 1][j] + int_ans[i][j + 1] - int_ans[i - 1][j + 1].Since, for a fixed a, the visiting order only depends on the starting city, the number of a for the interval [i,j] is now int_ans[i][j] / (j - i + 1).You have solved k≥1. The answer for k=0 is just nn minus all the other answers.O(n3) DPIn the previous section, you are running the same DP for O(n2) different "bound arrays" on the ai (in particular, O(n) arrays for each k). Now you want to solve a single k with a single DP.For a fixed k, you can notice that, if you run the DP on an array of length 2n instead of n, the bound array obtained from I=[n−k+1,n] contains all the bound arrays you wanted as subarrays of length n. So you can run the DP and get all the results as dp[i][i + n - 1][0].O(n2) DPYou still have O(n3) distinct states in total. How to make "bound arrays" simpler?It turns out that you can handle l and r differently! You can create bound arrays only based on r (and get O(n2) distinct states), and find l using the Corollary of Lemma 2. The transitions before finding l are very simple (you always go to the left). So a possible way to get O(n2) complexity is processing Strategy 1 and the DP in reverse order (from time n to time 1).Complexity: O(n2)

Prompt explanation + problem (separately):Use this technique below: for each number from 1 to n, maintain two arrays start and end , signifying the index of the first and last occurrence of the number. if there is no occurrence initiate it as -1. fact: there must exist a subarray of size j such that all occurrences of numbers upto j occurs inside that subarray for all j from 1 to n. Now the given array is valid iff it passes the following procedure: first we start with 1, if there is no occurrence of 1 we ignore it, in general say the first and last occurrence of 1 is in l and r, then r — l + 1 <= 1, next we go to the occurrences of two, if no occurrence then same thing as before, otherwise r — l + 1 <= 2. note that this new r and l is obtained by extending the previous l and r by the first and last occurrences of this number 2, basically within this new range l..r all occurrence of 1 and 2 must be present. we keep doing this for all the elements and if we can reach the end without any violation then we can in fact start from somewhere. On the procedure of finding where we can start, but with an example: 6 3 3 5 4 5 1: no occurrence implying our staring range: 1 to n 2: no occurrence implying our starting range: intersect the range of 1 with the range of two ( 1 to n again), which is also 1 to n. 3: l = 2, r = 3, and this range of length two should be contained inside a subarray of length 3, there are two such subarrays, and in fact we can start from anywhere between 1 and 4 and still be able to cover this range, so our current starting range is the subarray range 1 to 4 intersected with 1 to n, which is just 1 to 4. 4: new range of all occurrences till 4 is 2 to 5, and only one subarray satisfied it with range 2 to 5, so our valid range is 1 to 4 intersected with 2 to 5 which is 2 to 4. 5: so on our final valid range is 2 to 4, so there are 3 valid starting points convert this logic into code

SpoilerThere are two cases for all the leaves that have to be removed. Case 1: The depth of some leaf is greater than d: we need to remove such leaves until the point where the remaining tree has all leaves with depth less than or equal to dCase 2: The depth of some leaf is less than d: we need to remove such leaves until the remaining tree has all leaves with depth greater than or equal to d

SpoilerThe two cases mentioned above are independent and can be solved separately.

SpoilerIt’s simple dynamic programming + simulation I will describe the dynamics for the less case here : We process d in increasing order. Suppose we have found less[i] for all i < d, how do we find less[d]? We will simulate the process : when we are at d we would already have simulated the process for all depths < d, hence we won’t have any leaf with depth < d — 1 at this point. We want to have no leaf with depth less than d. Hence we will now remove all leaves with depth = d — 1, and if any such removal creates a new leaf, it would surely have a depth < d, hence we would insert it too in our data structure(from where we pick up leaves and remove them: we can keep a set of pair<int,int> the first value being depth and the second being node). Note that every node can be removed at most once across all iterations on d giving an asymptotics of O(nlogn) for this part.We can find more[d] in the same way.

Div2 E / Div1 C  Tree Pruningsubmission

Problem ReductionWe can say that for each 1≤i≤n, we want to find the number of segments which contain it and then see how many i are contained in n segments.So, for each segment, we can add 1 in the range from l to r (since this segment contains every element inside this range). Our new problem is to add x=1 in the range from l to r, and after doing all such operations, find how many elements are =n.

Hint 1Think, how can we use the fact that we have to perform all the operations before seeing the array.

Hint 2Instead of just looping over l to r, we instead want to pass this information and get the real value later.

SolutionWe can accomplish this by difference array (application of prefix sum). We do : p[l]++; indicating that a segment is starting from here. and p[r + 1]--; indicating that a segment has finished here.After doing all operations, if we run a for loop and do : p[i] += p[i - 1]; (make p it's own prefix sum), then we have in reality added 1 in the range from l to r (if you consider there was only one operation, and then later see that it works for any number of operations). 

Understood?See number of submissions

